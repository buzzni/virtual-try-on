from typing import Union, Optional, Tuple, Dict, List
import aiofiles
import asyncio
import io
from google import genai
from google.genai import types
from PIL import Image
import numpy as np
from configs import settings
from core.litellm_hander.schema import LiteLLMUsageData


class GeminiProcesser:
    """Gemini APIë¥¼ ì‚¬ìš©í•œ Virtual Try-On ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    # í´ë˜ìŠ¤ ë ˆë²¨ ìƒìˆ˜
    MODEL_NAME = "gemini-2.5-flash-image"
    TASK_NAME = "virtual_tryon"
    
    # ê°€ê²© ì •ë³´ (USD)
    INPUT_PRICE_PER_1M_TOKENS = 0.35
    OUTPUT_PRICE_PER_1M_TOKENS = 30.00
    USD_TO_KRW_RATE = 1380
    
    # ì¬ì‹œë„ ì„¤ì •
    MAX_RETRIES = 3
    RETRY_DELAY = 2.0  # ì´ˆ
    RETRY_BACKOFF_MULTIPLIER = 2.0
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
    MAX_CONCURRENT_REQUESTS = 10  # ë™ì‹œ ìš”ì²­ ìµœëŒ€ ê°œìˆ˜
    
    # Safety settings (í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±)
    SAFETY_SETTINGS = [
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold=types.HarmBlockThreshold.OFF
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=types.HarmBlockThreshold.OFF
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=types.HarmBlockThreshold.OFF
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold=types.HarmBlockThreshold.OFF
        )
    ]
    
    def __init__(self, verbose: bool = True):
        """
        Args:
            verbose: ë¡œê¹… ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        self.client = genai.Client(api_key=settings.gemini_api_key)
        self.aio_client = self.client.aio
        self.verbose = verbose
        
    def _extract_image_from_response(self, response) -> Optional[bytes]:
        """ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ ë©”ì†Œë“œ"""
        if not hasattr(response, 'candidates') or not response.candidates:
            return None
        
        candidate = response.candidates[0]
        if not hasattr(candidate, 'content') or not hasattr(candidate.content, 'parts'):
            return None
        
        for part in candidate.content.parts:
            if hasattr(part, 'inline_data') and part.inline_data:
                if hasattr(part.inline_data, 'data'):
                    return part.inline_data.data
        
        return None
        
    def _create_usage_data(
        self,
        total_token_count: int = 0,
        prompt_token_count: int = 0,
        candidates_token_count: int = 0,
        cost_usd: float = 0.0,
        cost_krw: float = 0.0
    ) -> LiteLLMUsageData:
        """LiteLLMUsageData ìƒì„± í—¬í¼ ë©”ì†Œë“œ"""
        return LiteLLMUsageData(
            total_token_count=total_token_count,
            prompt_token_count=prompt_token_count,
            candidates_token_count=candidates_token_count,
            output_token_count=candidates_token_count,
            cached_content_token_count=0,
            thoughts_token_count=0,
            model_name=self.MODEL_NAME,
            cost_usd=round(cost_usd, 6),
            cost_krw=round(cost_krw, 2),
            task_name=self.TASK_NAME
        )
    
    def _extract_token_details(self, usage_metadata) -> Tuple[int, int]:
        """í† í° ì„¸ë¶€ì‚¬í•­ì„ ì¶”ì¶œí•˜ëŠ” í—¬í¼ ë©”ì†Œë“œ (í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë¶„ë¦¬)"""
        prompt_text_tokens = 0
        prompt_image_tokens = 0
        
        if hasattr(usage_metadata, 'prompt_tokens_details') and usage_metadata.prompt_tokens_details:
            for detail in usage_metadata.prompt_tokens_details:
                modality_str = str(detail.modality)
                if 'TEXT' in modality_str:
                    prompt_text_tokens = detail.token_count or 0
                elif 'IMAGE' in modality_str:
                    prompt_image_tokens += detail.token_count or 0
        
        return prompt_text_tokens, prompt_image_tokens
    
    def _split_images_by_view(
        self,
        result_image_list: List,
        front_has_images: bool,
        back_has_images: bool,
        image_count: int,
        include_side: bool
    ) -> Tuple[List, List, List]:
        """ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë·°ë³„ë¡œ ë¶„ë¦¬í•˜ëŠ” í—¬í¼ ë©”ì†Œë“œ"""
        front_images, back_images, side_images = [], [], []
        idx = 0
        
        if front_has_images:
            front_images = [img for img in result_image_list[idx:idx+image_count] if img is not None]
            idx += image_count
        
        if back_has_images:
            back_images = [img for img in result_image_list[idx:idx+image_count] if img is not None]
            idx += image_count
        
        if include_side and front_has_images:
            side_images = [img for img in result_image_list[idx:idx+image_count] if img is not None]
        
        return front_images, back_images, side_images


    async def create_image_content(self, image: Union[Image.Image, bytes, str], use_reize = False) -> str:
        if isinstance(image, str):
            async with aiofiles.open(image, "rb") as f:
                image_bytes = await f.read()
            data = types.Part.from_bytes(
                data=image_bytes,
                mime_type="image/png",
            )

        elif use_reize:
            data = Image.open(image)
            if data.width > 1024 or data.height > 1024:
                data.thumbnail([1024, 1024], Image.Resampling.LANCZOS)
            # PIL Imageë¥¼ PNG bytesë¡œ ë³€í™˜
            buffer = io.BytesIO()
            data.save(buffer, format='PNG')
            buffer.seek(0)
            data = types.Part.from_bytes(
                data=buffer.getvalue(),
                mime_type="image/png",
            )            
        elif isinstance(image, bytes):
            data = types.Part.from_bytes(
                data=image,
                mime_type="image/png",
            )
        elif isinstance(image, np.ndarray):
            pil_image = Image.fromarray(image)
            if pil_image.width > 1024 or pil_image.height > 1024:
                pil_image.thumbnail([1024, 1024], Image.Resampling.LANCZOS)
            # PIL Imageë¥¼ PNG bytesë¡œ ë³€í™˜
            buffer = io.BytesIO()
            pil_image.save(buffer, format='PNG')
            buffer.seek(0)
            data = types.Part.from_bytes(
                data=buffer.getvalue(),
                mime_type="image/png",
            )
        else:
            # PIL Imageë¥¼ PNG bytesë¡œ ë³€í™˜
            buffer = io.BytesIO()
            image.save(buffer, format='PNG')
            buffer.seek(0)
            data = types.Part.from_bytes(
                data=buffer.getvalue(),
                mime_type="image/png",
            )
        return data

    async def virtual_tryon_inference(self, contents, temperature: float = 1.0, top_p: float = 0.95):
        """
        ë‹¨ì¼ Virtual Try-On ì¶”ë¡  (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            contents: ì…ë ¥ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ë“¤)
            temperature: ê²°ê³¼ì˜ ë‹¤ì–‘ì„±
            top_p: Top-p (nucleus) ìƒ˜í”Œë§ ê°’ (ê¸°ë³¸ê°’: 0.95)
        
        Returns:
            tuple: (ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°, ë¹„ìš© ì •ë³´)
        """
        last_exception = None
        delay = self.RETRY_DELAY
        
        for attempt in range(self.MAX_RETRIES):
            try:
                # Gemini API í˜¸ì¶œ (ì´ë¯¸ì§€ë§Œ ìƒì„±í•˜ë„ë¡ ì„¤ì •)
                response = await self.aio_client.models.generate_content(
                    model=self.MODEL_NAME,
                    contents=contents,
                    config=types.GenerateContentConfig(
                        response_modalities=[types.Modality.IMAGE],
                        temperature=temperature,
                        top_p=top_p,
                        image_config=types.ImageConfig(aspect_ratio="1:1"),
                        safety_settings=self.SAFETY_SETTINGS
                    )
                )
                
                # ë¹„ìš© ê³„ì‚°
                usage_data = await self.calculate_vto_cost(
                    response.usage_metadata if hasattr(response, 'usage_metadata') else None
                )
                
                # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
                image_data = self._extract_image_from_response(response)
                return image_data, usage_data
                
            except Exception as e:
                last_exception = e
                error_str = str(e)
                
                # 502, 503, 429 ë“± ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
                is_retryable = any(code in error_str for code in ['502', '503', '429', 'Bad Gateway', 'Service Unavailable', 'Too Many Requests'])
                
                if is_retryable and attempt < self.MAX_RETRIES - 1:
                    if self.verbose:
                        print(f"âš ï¸  ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ ë°œìƒ (ì‹œë„ {attempt + 1}/{self.MAX_RETRIES}): {error_str[:100]}")
                        print(f"   {delay}ì´ˆ í›„ ì¬ì‹œë„...")
                    
                    await asyncio.sleep(delay)
                    delay *= self.RETRY_BACKOFF_MULTIPLIER
                else:
                    if self.verbose:
                        print(f"âŒ Inference Error (ì‹œë„ {attempt + 1}/{self.MAX_RETRIES}): {error_str[:200]}")
                    break
        
        return None, None
    
    async def calculate_vto_cost(self, usage_metadata) -> LiteLLMUsageData:
        """
        Gemini 2.5 Flash Image ëª¨ë¸ì˜ í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
        
        Args:
            usage_metadata: Gemini API ì‘ë‹µì˜ ì‚¬ìš©ëŸ‰ ë©”íƒ€ë°ì´í„°
        
        Returns:
            LiteLLMUsageData: í† í° ë° ë¹„ìš© ì •ë³´
        """
        if not usage_metadata:
            return self._create_usage_data()
        
        # None ê°’ ë°©ì–´ ì²˜ë¦¬
        prompt_token_count = usage_metadata.prompt_token_count or 0
        candidates_token_count = usage_metadata.candidates_token_count or 0
        total_token_count = usage_metadata.total_token_count or 0
        
        # ë¹„ìš© ê³„ì‚°
        input_cost = (prompt_token_count / 1_000_000) * self.INPUT_PRICE_PER_1M_TOKENS
        output_cost = (candidates_token_count / 1_000_000) * self.OUTPUT_PRICE_PER_1M_TOKENS
        total_cost = input_cost + output_cost
        total_cost_krw = total_cost * self.USD_TO_KRW_RATE
        
        # ë””ë²„ê¹… ë¡œê·¸ (verbose ëª¨ë“œì¼ ë•Œë§Œ)
        if self.verbose:
            prompt_text_tokens, prompt_image_tokens = self._extract_token_details(usage_metadata)
            print(f"\n=== í† í° ì‚¬ìš©ëŸ‰ ìƒì„¸ ===")
            print(f"ì…ë ¥ í† í°: {prompt_token_count} (í…ìŠ¤íŠ¸: {prompt_text_tokens}, ì´ë¯¸ì§€: {prompt_image_tokens})")
            print(f"ì¶œë ¥ í† í°: {candidates_token_count}")
            print(f"ì´ í† í°: {total_token_count}")
            print(f"ì…ë ¥ ë¹„ìš©: ${input_cost:.6f}")
            print(f"ì¶œë ¥ ë¹„ìš©: ${output_cost:.6f}")
            print(f"ì´ ë¹„ìš©: ${total_cost:.6f} (ì•½ {total_cost_krw:,.2f}ì›)")
            print(f"======================\n")
        
        return self._create_usage_data(
            total_token_count=total_token_count,
            prompt_token_count=prompt_token_count,
            candidates_token_count=candidates_token_count,
            cost_usd=total_cost,
            cost_krw=total_cost_krw
        )
        
    async def sum_usage_data(self, usage_data_list: List[LiteLLMUsageData]) -> LiteLLMUsageData:
        """
        ì—¬ëŸ¬ LiteLLMUsageDataë¥¼ í•©ì‚°
        
        Args:
            usage_data_list: LiteLLMUsageData ë¦¬ìŠ¤íŠ¸
        
        Returns:
            LiteLLMUsageData: í•©ì‚°ëœ ë¹„ìš© ì •ë³´
        """
        return self._create_usage_data(
            total_token_count=sum(u.total_token_count for u in usage_data_list),
            prompt_token_count=sum(u.prompt_token_count for u in usage_data_list),
            candidates_token_count=sum(u.candidates_token_count for u in usage_data_list),
            cost_usd=sum(u.cost_usd for u in usage_data_list),
            cost_krw=sum(u.cost_krw for u in usage_data_list)
        )
    
    async def load_clothes_images(
        self,
        front_image_path: Optional[str],
        back_image_path: Optional[str]
    ) -> Tuple[Optional[Image.Image], Optional[Image.Image]]:
        """
        ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        
        Args:
            front_image_path: ì•ë©´ ì˜ë¥˜ ì´ë¯¸ì§€ ê²½ë¡œ
            back_image_path: ë’·ë©´ ì˜ë¥˜ ì´ë¯¸ì§€ ê²½ë¡œ
        
        Returns:
            Tuple: (ì•ë©´ ì´ë¯¸ì§€, ë’·ë©´ ì´ë¯¸ì§€)
        """
        front_clothes_img = Image.open(front_image_path) if front_image_path else None
        back_clothes_img = Image.open(back_image_path) if back_image_path else None
        return front_clothes_img, back_clothes_img

    async def _run_with_semaphore(self, semaphore: asyncio.Semaphore, contents, temperature: float, top_p: float):
        """ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ìš”ì²­ ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” í—¬í¼ ë©”ì†Œë“œ"""
        async with semaphore:
            return await self.virtual_tryon_inference(contents, temperature, top_p)
    
    async def execute_vto_inference(
        self,
        contents_list: List,
        front_has_images: bool,
        back_has_images: bool,
        image_count: int,
        temperature: float,
        include_side: bool = False,
        top_p: float = 0.95
    ) -> Dict:
        """
        Virtual Try-On ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê³µí†µ ë¡œì§
        (ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ ë° ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            contents_list: Gemini APIì— ì „ë‹¬í•  ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
            front_has_images: ì•ë©´ ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€
            back_has_images: ë’·ë©´ ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€
            image_count: ìƒì„±í•  ì´ë¯¸ì§€ ê°œìˆ˜
            temperature: ê²°ê³¼ì˜ ë‹¤ì–‘ì„±
            include_side: ì¸¡ë©´ ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€
            top_p: Top-p (nucleus) ìƒ˜í”Œë§ ê°’ (ê¸°ë³¸ê°’: 0.95)
        
        Returns:
            Dict: ì‘ë‹µ ê²°ê³¼ (ì•ë©´/ë’·ë©´/ì¸¡ë©´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ë° ë¹„ìš© ì •ë³´)
        """
        if self.verbose:
            print(f"\n{'='*50}")
            print(f"ğŸ“¸ ì´ ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜: {len(contents_list)}")
            print(f"âš™ï¸  ë™ì‹œ ìš”ì²­ ì œí•œ: ìµœëŒ€ {self.MAX_CONCURRENT_REQUESTS}ê°œ")
            print(f"ğŸ”„ ì¬ì‹œë„ ì„¤ì •: ìµœëŒ€ {self.MAX_RETRIES}íšŒ, ì´ˆê¸° ëŒ€ê¸° {self.RETRY_DELAY}ì´ˆ")
            print(f"ğŸ”„ Top-p: {top_p}")
            print(f"ğŸ”„ Temperature: {temperature}")
            print(f"{'='*50}\n")
        
        # ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_REQUESTS)
        
        # ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ ë³‘ë ¬ í˜¸ì¶œ (ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ)
        tasks = [self._run_with_semaphore(semaphore, contents, temperature, top_p) for contents in contents_list]
        responses = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ ë¶„ë¦¬
        result_image_list, usage_data_list = zip(*responses) if responses else ([], [])
        
        # Noneì´ ì•„ë‹Œ usage_dataë§Œ í•„í„°ë§í•˜ì—¬ ë¹„ìš© í•©ì‚°
        valid_usage_data = [usage for usage in usage_data_list if usage is not None]
        total_usage = await self.sum_usage_data(valid_usage_data) if valid_usage_data else await self.calculate_vto_cost(None)
        
        # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë·°ë³„ë¡œ ë¶„ë¦¬
        front_images, back_images, side_images = self._split_images_by_view(
            result_image_list, front_has_images, back_has_images, image_count, include_side
        )
        
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹¨
        all_images = front_images + back_images + (side_images if include_side else [])
        
        # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
        success_count = len([img for img in result_image_list if img is not None])
        fail_count = len(result_image_list) - success_count
        
        if self.verbose:
            print(f"\n{'='*50}")
            print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
            if fail_count > 0:
                print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
            print(f"{'='*50}\n")
        
        return {
            "response": all_images,
            "front_images": front_images,
            "back_images": back_images,
            "side_images": side_images if include_side else [],
            "usage": total_usage,
            "debug_info": {
                "front_count": len(front_images),
                "back_count": len(back_images),
                "side_count": len(side_images) if include_side else 0,
                "total_count": len(all_images),
                "requested_count_per_view": image_count,
                "success_count": success_count,
                "fail_count": fail_count,
                "model_name": self.MODEL_NAME,
            }
        }