from typing import Union, Optional, Tuple, Dict, List
import aiofiles
import asyncio
import io
from google import genai
from google.genai import types
from PIL import Image
import numpy as np
from configs import settings
from core.litellm_hander.schema import LiteLLMUsageData


class GeminiProcesser:
    """Gemini APIë¥¼ ì‚¬ìš©í•œ Virtual Try-On ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    # í´ë˜ìŠ¤ ë ˆë²¨ ìƒìˆ˜
    MODEL_NAME = "gemini-2.5-flash-image"
    TASK_NAME = "virtual_tryon"
    
    # ê°€ê²© ì •ë³´ (USD)
    INPUT_PRICE_PER_1M_TOKENS = 0.35
    OUTPUT_PRICE_PER_1M_TOKENS = 30.00
    USD_TO_KRW_RATE = 1380
    
    # ì¬ì‹œë„ ì„¤ì •
    MAX_RETRIES = 3
    RETRY_DELAY = 2.0  # ì´ˆ
    RETRY_BACKOFF_MULTIPLIER = 2.0
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
    MAX_CONCURRENT_REQUESTS = 10  # ë™ì‹œ ìš”ì²­ ìµœëŒ€ ê°œìˆ˜
    
    # Safety settings (í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±)
    SAFETY_SETTINGS = [
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold=types.HarmBlockThreshold.OFF
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=types.HarmBlockThreshold.OFF
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=types.HarmBlockThreshold.OFF
        ),
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold=types.HarmBlockThreshold.OFF
        )
    ]
    
    def __init__(self, verbose: bool = True):
        """
        Args:
            verbose: ë¡œê¹… ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        self.client = genai.Client(api_key=settings.gemini_api_key)
        self.aio_client = self.client.aio
        self.verbose = verbose
        
    @staticmethod
    def _pil_to_png_bytes(image: Image.Image) -> bytes:
        """PIL Imageë¥¼ PNG bytesë¡œ ë³€í™˜"""
        buffer = io.BytesIO()
        image.save(buffer, format='PNG')
        return buffer.getvalue()
    
    @staticmethod
    def _extract_image_from_response(response) -> Optional[bytes]:
        """ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ"""
        try:
            return response.candidates[0].content.parts[0].inline_data.data
        except (AttributeError, IndexError):
            return None
    
    def _create_usage_data(self, total_token_count: int = 0, prompt_token_count: int = 0,
                        candidates_token_count: int = 0, cost_usd: float = 0.0,
                        cost_krw: float = 0.0) -> LiteLLMUsageData:
        """LiteLLMUsageData ìƒì„±"""
        return LiteLLMUsageData(
            total_token_count=total_token_count,
            prompt_token_count=prompt_token_count,
            candidates_token_count=candidates_token_count,
            output_token_count=candidates_token_count,
            cached_content_token_count=0,
            thoughts_token_count=0,
            model_name=self.MODEL_NAME,
            cost_usd=round(cost_usd, 6),
            cost_krw=round(cost_krw, 2),
            task_name=self.TASK_NAME
        )
    
    @staticmethod
    def _extract_token_details(usage_metadata) -> Tuple[int, int]:
        """í† í° ì„¸ë¶€ì‚¬í•­ ì¶”ì¶œ (í…ìŠ¤íŠ¸/ì´ë¯¸ì§€)"""
        text_tokens = image_tokens = 0
        
        if hasattr(usage_metadata, 'prompt_tokens_details') and usage_metadata.prompt_tokens_details:
            for detail in usage_metadata.prompt_tokens_details:
                if 'TEXT' in str(detail.modality):
                    text_tokens = detail.token_count or 0
                elif 'IMAGE' in str(detail.modality):
                    image_tokens += detail.token_count or 0
        
        return text_tokens, image_tokens

    async def create_image_content(self, image: Union[Image.Image, bytes, str, np.ndarray], 
                                use_resize: bool = False) -> types.Part:
        """ì´ë¯¸ì§€ë¥¼ Gemini API í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        
        # ë¬¸ìì—´ ê²½ë¡œì¸ ê²½ìš°: íŒŒì¼ ì½ê¸°
        if isinstance(image, str):
            async with aiofiles.open(image, "rb") as f:
                image_bytes = await f.read()
            return types.Part.from_bytes(data=image_bytes, mime_type="image/png")
        
        # bytesì¸ ê²½ìš°: ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if isinstance(image, bytes):
            return types.Part.from_bytes(data=image, mime_type="image/png")
        
        # numpy arrayì¸ ê²½ìš°: PIL Imageë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # PIL Image ì²˜ë¦¬ (resize ì˜µì…˜ ì ìš©)
        if use_resize and (image.width > 1024 or image.height > 1024):
            image.thumbnail([1024, 1024], Image.Resampling.LANCZOS)
        
        return types.Part.from_bytes(
            data=self._pil_to_png_bytes(image),
            mime_type="image/png"
        )
    
    async def calculate_vto_cost(self, usage_metadata) -> LiteLLMUsageData:
        """
        Gemini 2.5 Flash Image ëª¨ë¸ì˜ í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
        
        Args:
            usage_metadata: Gemini API ì‘ë‹µì˜ ì‚¬ìš©ëŸ‰ ë©”íƒ€ë°ì´í„°
        
        Returns:
            LiteLLMUsageData: í† í° ë° ë¹„ìš© ì •ë³´
        """
        if not usage_metadata:
            return self._create_usage_data()
        
        # None ê°’ ë°©ì–´ ì²˜ë¦¬
        prompt_token_count = usage_metadata.prompt_token_count or 0
        candidates_token_count = usage_metadata.candidates_token_count or 0
        total_token_count = usage_metadata.total_token_count or 0
        
        # ë¹„ìš© ê³„ì‚°
        input_cost = (prompt_token_count / 1_000_000) * self.INPUT_PRICE_PER_1M_TOKENS
        output_cost = (candidates_token_count / 1_000_000) * self.OUTPUT_PRICE_PER_1M_TOKENS
        total_cost = input_cost + output_cost
        total_cost_krw = total_cost * self.USD_TO_KRW_RATE
        
        # ë””ë²„ê¹… ë¡œê·¸ (verbose ëª¨ë“œì¼ ë•Œë§Œ)
        if self.verbose:
            prompt_text_tokens, prompt_image_tokens = self._extract_token_details(usage_metadata)
            print(f"\n=== í† í° ì‚¬ìš©ëŸ‰ ìƒì„¸ ===")
            print(f"ì…ë ¥ í† í°: {prompt_token_count} (í…ìŠ¤íŠ¸: {prompt_text_tokens}, ì´ë¯¸ì§€: {prompt_image_tokens})")
            print(f"ì¶œë ¥ í† í°: {candidates_token_count}")
            print(f"ì´ í† í°: {total_token_count}")
            print(f"ì…ë ¥ ë¹„ìš©: ${input_cost:.6f}")
            print(f"ì¶œë ¥ ë¹„ìš©: ${output_cost:.6f}")
            print(f"ì´ ë¹„ìš©: ${total_cost:.6f} (ì•½ {total_cost_krw:,.2f}ì›)")
            print(f"======================\n")
        
        return self._create_usage_data(
            total_token_count=total_token_count,
            prompt_token_count=prompt_token_count,
            candidates_token_count=candidates_token_count,
            cost_usd=total_cost,
            cost_krw=total_cost_krw
        )
        
    async def sum_usage_data(self, usage_data_list: List[LiteLLMUsageData]) -> LiteLLMUsageData:
        """
        ì—¬ëŸ¬ LiteLLMUsageDataë¥¼ í•©ì‚°
        
        Args:
            usage_data_list: LiteLLMUsageData ë¦¬ìŠ¤íŠ¸
        
        Returns:
            LiteLLMUsageData: í•©ì‚°ëœ ë¹„ìš© ì •ë³´
        """
        return self._create_usage_data(
            total_token_count=sum(u.total_token_count for u in usage_data_list),
            prompt_token_count=sum(u.prompt_token_count for u in usage_data_list),
            candidates_token_count=sum(u.candidates_token_count for u in usage_data_list),
            cost_usd=sum(u.cost_usd for u in usage_data_list),
            cost_krw=sum(u.cost_krw for u in usage_data_list)
        )
    
    async def load_clothes_images(
        self,
        image_path: Optional[str],
    ) -> Optional[Image.Image]:
        """
        ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        
        Args:
            image_path: ì˜ë¥˜ ì´ë¯¸ì§€ ê²½ë¡œ
        
        Returns:
            Optional[Image.Image]: ì˜ë¥˜ ì´ë¯¸ì§€
        """
        clothes_img = Image.open(image_path) if image_path else None
        return clothes_img

    async def gemini_image_inference(self, contents, temperature: float = 1.0, top_p: float = 0.95, aspect_ratio: str = "1:1"):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡  (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            contents: ì…ë ¥ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ë“¤)
            temperature: ê²°ê³¼ì˜ ë‹¤ì–‘ì„±
            top_p: Top-p (nucleus) ìƒ˜í”Œë§ ê°’ (ê¸°ë³¸ê°’: 0.95)
        
        Returns:
            tuple: (ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°, ë¹„ìš© ì •ë³´)
        """
        delay = self.RETRY_DELAY
        
        for attempt in range(self.MAX_RETRIES):
            try:
                # Gemini API í˜¸ì¶œ (ì´ë¯¸ì§€ë§Œ ìƒì„±í•˜ë„ë¡ ì„¤ì •)
                response = await self.aio_client.models.generate_content(
                    model=self.MODEL_NAME,
                    contents=contents,
                    config=types.GenerateContentConfig(
                        response_modalities=[types.Modality.IMAGE],
                        temperature=temperature,
                        top_p=top_p,
                        image_config=types.ImageConfig(aspect_ratio=aspect_ratio),
                        safety_settings=self.SAFETY_SETTINGS
                    )
                )
                
                # ë¹„ìš© ê³„ì‚°
                usage_data = await self.calculate_vto_cost(
                    response.usage_metadata if hasattr(response, 'usage_metadata') else None
                )
                
                # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
                image_data = self._extract_image_from_response(response)
                return image_data, usage_data
                
            except Exception as e:
                error_str = str(e)
                
                # 502, 503, 429 ë“± ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
                is_retryable = any(code in error_str for code in ['502', '503', '429', 'Bad Gateway', 'Service Unavailable', 'Too Many Requests'])
                
                if is_retryable and attempt < self.MAX_RETRIES - 1:
                    if self.verbose:
                        print(f"âš ï¸  ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ ë°œìƒ (ì‹œë„ {attempt + 1}/{self.MAX_RETRIES}): {error_str[:100]}")
                        print(f"   {delay}ì´ˆ í›„ ì¬ì‹œë„...")
                    
                    await asyncio.sleep(delay)
                    delay *= self.RETRY_BACKOFF_MULTIPLIER
                else:
                    if self.verbose:
                        print(f"âŒ Inference Error (ì‹œë„ {attempt + 1}/{self.MAX_RETRIES}): {error_str[:200]}")
                    break
        
        return None, None
    
    async def _run_with_semaphore(self, semaphore: asyncio.Semaphore, contents, temperature: float, top_p: float, aspect_ratio: str):
        """ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ìš”ì²­ ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” í—¬í¼ ë©”ì†Œë“œ"""
        async with semaphore:
            return await self.gemini_image_inference(contents, temperature, top_p, aspect_ratio)
        
    async def execute_image_inference(
        self,
        contents_list: List,
        image_count: int,
        temperature: float,
        top_p: float = 0.95,
        aspect_ratio: str = "1:1"
    ) -> Dict:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê³µí†µ ë¡œì§
        (ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ ë° ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            contents_list: Gemini APIì— ì „ë‹¬í•  ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
            temperature: ê²°ê³¼ì˜ ë‹¤ì–‘ì„±
            top_p: Top-p (nucleus) ìƒ˜í”Œë§ ê°’ (ê¸°ë³¸ê°’: 0.95)
        
        Returns:
            Dict: ì‘ë‹µ ê²°ê³¼ (ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ë° ë¹„ìš© ì •ë³´)
        """
        if self.verbose:
            print(f"\n{'='*50}")
            print(f"ğŸ“¸ ì´ ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜: {image_count}")
            print(f"âš™ï¸  ë™ì‹œ ìš”ì²­ ì œí•œ: ìµœëŒ€ {self.MAX_CONCURRENT_REQUESTS}ê°œ")
            print(f"ğŸ”„ ì¬ì‹œë„ ì„¤ì •: ìµœëŒ€ {self.MAX_RETRIES}íšŒ, ì´ˆê¸° ëŒ€ê¸° {self.RETRY_DELAY}ì´ˆ")
            print(f"ğŸ”„ Top-p: {top_p}")
            print(f"ğŸ”„ Temperature: {temperature}")
            print(f"{'='*50}\n")
        
        # ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_REQUESTS)
        
        recursive_contents_list = []
        for _ in range(image_count):
            recursive_contents_list.append(contents_list)
        
        # ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ ë³‘ë ¬ í˜¸ì¶œ (ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ)
        tasks = [self._run_with_semaphore(semaphore, contents, temperature, top_p, aspect_ratio) for contents in recursive_contents_list]
        responses = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ ë¶„ë¦¬
        result_image_list, usage_data_list = zip(*responses) if responses else ([], [])
        
        # Noneì´ ì•„ë‹Œ usage_dataë§Œ í•„í„°ë§í•˜ì—¬ ë¹„ìš© í•©ì‚°
        valid_usage_data = [usage for usage in usage_data_list if usage is not None]
        total_usage = await self.sum_usage_data(valid_usage_data) if valid_usage_data else await self.calculate_vto_cost(None)
        
        all_images = result_image_list
        
        # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
        success_count = len([img for img in result_image_list if img is not None])
        fail_count = len(result_image_list) - success_count
        
        if self.verbose:
            print(f"\n{'='*50}")
            print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
            if fail_count > 0:
                print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
            print(f"{'='*50}\n")
        
        return {
            "response": all_images,
            "usage": total_usage,
            "debug_info": {
                "total_count": len(all_images),
                "success_count": success_count,
                "fail_count": fail_count,
                "model_name": self.MODEL_NAME,
            }
        }